<NeuralNetwork>
    <Inputs>
        <InputsNumber>21</InputsNumber>
        <Item Index="1">
            <Name>input_1</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="2">
            <Name>input_2</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="3">
            <Name>input_3</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="4">
            <Name>input_4</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="5">
            <Name>input_5</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="6">
            <Name>input_6</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="7">
            <Name>input_7</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="8">
            <Name>input_8</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="9">
            <Name>input_9</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="10">
            <Name>input_10</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="11">
            <Name>input_11</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="12">
            <Name>input_12</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="13">
            <Name>input_13</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="14">
            <Name>input_14</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="15">
            <Name>input_15</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="16">
            <Name>input_16</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="17">
            <Name>input_17</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="18">
            <Name>input_18</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="19">
            <Name>input_19</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="20">
            <Name>input_20</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="21">
            <Name>input_21</Name>
            <Units></Units>
            <Description></Description>
        </Item>
    </Inputs>
    <ScalingLayer>
        <ScalingNeuronsNumber>21</ScalingNeuronsNumber>
        <Statistics Index="1">
            <Minimum>0.013434</Minimum>
            <Maximum>0.24291</Maximum>
            <Mean>0.0578487</Mean>
            <StandardDeviation>0.046053</StandardDeviation>
        </Statistics>
        <Statistics Index="2">
            <Minimum>-77.573</Minimum>
            <Maximum>-50.0265</Maximum>
            <Mean>-65.392</Mean>
            <StandardDeviation>8.26131</StandardDeviation>
        </Statistics>
        <Statistics Index="3">
            <Minimum>-0.769239</Minimum>
            <Maximum>8.1985</Maximum>
            <Mean>4.26281</Mean>
            <StandardDeviation>1.74461</StandardDeviation>
        </Statistics>
        <Statistics Index="4">
            <Minimum>-1.60061</Minimum>
            <Maximum>2.69304</Maximum>
            <Mean>0.403561</Mean>
            <StandardDeviation>0.714483</StandardDeviation>
        </Statistics>
        <Statistics Index="5">
            <Minimum>-1.41077</Minimum>
            <Maximum>1.59887</Maximum>
            <Mean>0.439041</Mean>
            <StandardDeviation>0.485767</StandardDeviation>
        </Statistics>
        <Statistics Index="6">
            <Minimum>-1.17057</Minimum>
            <Maximum>2.49429</Maximum>
            <Mean>0.0668763</Mean>
            <StandardDeviation>0.479453</StandardDeviation>
        </Statistics>
        <Statistics Index="7">
            <Minimum>-1.30067</Minimum>
            <Maximum>1.87823</Maximum>
            <Mean>0.205136</Mean>
            <StandardDeviation>0.505053</StandardDeviation>
        </Statistics>
        <Statistics Index="8">
            <Minimum>1e-06</Minimum>
            <Maximum>0.001568</Maximum>
            <Mean>0.000135269</Mean>
            <StandardDeviation>0.000161697</StandardDeviation>
        </Statistics>
        <Statistics Index="9">
            <Minimum>1.15129</Minimum>
            <Maximum>3.1056</Maximum>
            <Mean>1.51458</Mean>
            <StandardDeviation>0.305331</StandardDeviation>
        </Statistics>
        <Statistics Index="10">
            <Minimum>1.39951</Minimum>
            <Maximum>18.0986</Maximum>
            <Mean>3.58271</Mean>
            <StandardDeviation>2.60529</StandardDeviation>
        </Statistics>
        <Statistics Index="11">
            <Minimum>0.230231</Minimum>
            <Maximum>0.910904</Maximum>
            <Mean>0.435664</Mean>
            <StandardDeviation>0.102915</StandardDeviation>
        </Statistics>
        <Statistics Index="12">
            <Minimum>0.162161</Minimum>
            <Maximum>0.649395</Maximum>
            <Mean>0.335533</Mean>
            <StandardDeviation>0.0724693</StandardDeviation>
        </Statistics>
        <Statistics Index="13">
            <Minimum>1e-06</Minimum>
            <Maximum>0.001108</Maximum>
            <Mean>0.000220101</Mean>
            <StandardDeviation>0.00018833</StandardDeviation>
        </Statistics>
        <Statistics Index="14">
            <Minimum>0.136879</Minimum>
            <Maximum>18.1338</Maximum>
            <Mean>1.95618</Mean>
            <StandardDeviation>2.40108</StandardDeviation>
        </Statistics>
        <Statistics Index="15">
            <Minimum>0.162518</Minimum>
            <Maximum>2.84069</Maximum>
            <Mean>1.2734</Mean>
            <StandardDeviation>0.478274</StandardDeviation>
        </Statistics>
        <Statistics Index="16">
            <Minimum>0.021436</Minimum>
            <Maximum>0.990236</Maximum>
            <Mean>0.256069</Mean>
            <StandardDeviation>0.160839</StandardDeviation>
        </Statistics>
        <Statistics Index="17">
            <Minimum>1e-06</Minimum>
            <Maximum>0.001545</Maximum>
            <Mean>0.000113008</Mean>
            <StandardDeviation>0.00016943</StandardDeviation>
        </Statistics>
        <Statistics Index="18">
            <Minimum>1e-06</Minimum>
            <Maximum>0.001538</Maximum>
            <Mean>0.000109704</Mean>
            <StandardDeviation>0.000166595</StandardDeviation>
        </Statistics>
        <Statistics Index="19">
            <Minimum>0.041827</Minimum>
            <Maximum>13.7892</Maximum>
            <Mean>1.80024</Mean>
            <StandardDeviation>2.52321</StandardDeviation>
        </Statistics>
        <Statistics Index="20">
            <Minimum>0.001143</Minimum>
            <Maximum>0.031338</Maximum>
            <Mean>0.00870924</Mean>
            <StandardDeviation>0.00535183</StandardDeviation>
        </Statistics>
        <Statistics Index="21">
            <Minimum>0.05916</Minimum>
            <Maximum>0.274063</Maximum>
            <Mean>0.133814</Mean>
            <StandardDeviation>0.0337575</StandardDeviation>
        </Statistics>
        <ScalingMethod>MinimumMaximum</ScalingMethod>
    </ScalingLayer>
    <MultilayerPerceptron>
        <Architecture>21 30 3</Architecture>
        <LayersActivationFunction>HyperbolicTangent Linear</LayersActivationFunction>
        <Parameters>0.336802 0.121669 0.43348 -0.991732 0.208443 -1.31608 0.140038 -1.23481 -0.810184 0.793375 0.987617 -0.0674929 -0.267296 -0.559882 -2.81427 -0.00313052 -0.924203 -0.0350355 0.615831 0.338095 -1.894 -0.332966 0.113137 -0.499816 1.29023 0.699005 -0.80772 1.48849 0.333362 -0.445282 -0.042627 -0.36268 -0.538147 0.494109 -0.143878 -0.424329 -0.378716 -0.680189 -0.808224 -1.53873 -0.8571 -1.02131 2.43346 -1.33494 1.66356 1.15297 1.18893 -0.0317687 0.0288401 -0.0751708 -0.141743 -0.768686 0.089974 0.560356 -0.976289 -0.385747 2.22609 -1.55833 -0.438041 -0.391184 -0.132487 0.00885186 -0.925633 -1.10899 -1.57549 0.905288 -0.352978 0.997709 -1.05678 -1.83677 -1.31932 -0.561369 -0.890465 -0.432841 -0.835726 -0.464717 1.05153 1.03449 0.393344 -0.0458634 -0.184437 -1.16465 -1.37765 0.739153 0.352633 0.00635626 0.631572 1.60132 0.00651993 1.23311 -3.39867 -1.07357 0.301168 -0.574308 1.11792 0.206851 1.05743 1.21383 0.459769 -0.224141 -0.333403 0.507342 -0.00223102 -0.0269413 -0.422917 -0.385413 -0.295728 0.758555 -1.14893 0.0187996 -1.24339 0.121734 -0.60877 -0.354098 0.156534 0.946552 -1.76329 -0.810944 0.0710518 0.186741 0.0727098 0.543281 0.873781 0.185927 -0.58981 -1.00878 0.202477 -1.64059 2.00432 0.137149 0.625251 1.85608 0.942649 -0.51857 -1.96544 -1.5238 0.277688 -0.82668 -0.19059 -0.743032 0.113359 -1.1231 0.712868 -1.08488 -0.207133 -2.18283 -0.456379 -1.00412 -1.7959 0.858253 -1.71089 0.0342456 -2.35009 1.11882 -0.575281 1.77598 -0.568045 -0.450083 0.108475 0.997551 0.495278 -1.40541 -0.818621 0.693027 0.0295823 -0.918593 -0.314981 0.887415 -0.216894 -1.33546 -0.149055 -0.259348 -0.860644 0.0707038 1.78411 -0.26386 -0.604631 -0.0010011 0.339563 -1.33463 1.05679 -0.567352 -0.629526 -0.904577 -0.588078 1.00602 -0.169324 -0.288701 1.62997 -0.214153 -0.829321 -1.10678 0.129983 -0.729121 1.12329 1.13398 -0.839852 0.754774 1.18235 1.11258 -0.588457 -0.897057 -0.0499291 0.235623 -0.63302 -1.69046 0.466276 -1.23737 -1.34905 -1.09958 -0.115369 0.930513 0.140833 0.883563 0.681894 0.457048 0.192899 0.185724 -0.60479 -2.04629 3.32147 -0.385896 -0.137842 1.07893 -0.520639 -1.04504 0.240709 -0.314631 0.168868 0.0368924 0.870638 0.0445398 -0.289314 0.487579 1.64552 -0.622067 0.953768 0.228663 -2.11033 -0.29757 0.163833 -0.735084 -0.412796 0.00180265 -3.43753 -0.884262 -1.25907 1.02684 -0.82763 0.365878 -0.0581617 -0.945889 -0.569618 -0.423806 0.799111 -0.513844 1.48201 0.14559 0.566 -1.37475 -0.596575 0.954882 0.350906 1.36691 -0.660761 -0.235775 -2.41552 -0.797073 0.798925 -0.677497 0.239192 0.450563 -0.444641 -0.338054 -0.0470594 0.141009 1.83419 -1.08391 -0.0628949 -0.310013 -0.356947 1.68325 0.674309 -2.20902 -0.0949937 0.244905 1.09935 -0.288612 0.432762 -0.154483 0.785281 0.161596 -0.880607 0.00938734 0.328969 -0.603584 1.38574 -0.27809 -0.402035 0.829188 -1.22641 1.06277 -0.910881 -1.01546 -0.0221922 0.12394 -1.73615 -0.519382 1.19633 -0.181636 0.859132 0.746544 1.06825 0.583308 -0.617897 -0.197596 -1.35998 -1.28673 -0.481364 0.051373 -0.338242 1.32439 1.03473 -0.807241 -1.82717 -0.163524 -1.41395 -0.334599 -0.328446 1.09127 0.778562 -1.26558 -0.489433 -0.572907 0.54821 0.228251 1.17127 1.2599 1.30985 -0.0773205 -1.78363 0.468815 1.10471 0.0743184 0.371571 -1.1169 -1.41456 -1.11896 -1.66242 0.628072 -0.378005 0.0128757 -1.67603 -1.75831 -0.651366 1.03175 0.767967 -1.71504 0.351748 0.0489881 0.347769 0.060196 0.775907 0.62837 -0.958217 -0.644141 1.28811 0.213001 -1.40647 1.08509 0.177186 0.734771 1.2784 -0.0768131 1.00131 0.469974 -1.97619 1.0965 -0.338137 1.0612 -0.796355 1.28376 0.941039 -2.77547 -0.465618 0.175483 -1.13542 -1.67862 0.349203 0.238457 -0.935866 1.06912 -0.689319 -1.27372 0.00264538 0.705442 -2.12256 0.180559 0.758268 -1.97623 -0.401844 0.192744 0.965784 -0.316632 -0.253691 0.704496 -1.39296 0.427375 -0.35732 -1.29277 0.858967 -0.0276141 -0.291633 0.937237 -1.70036 -0.781173 0.182707 -0.204973 -0.646355 0.227736 -0.106404 -2.00343 -0.00620822 0.301791 -0.464469 1.74439 2.75765 0.345285 -1.28099 1.75829 1.01172 -0.434485 0.119814 0.673509 1.08077 0.193528 0.0491412 0.408462 0.993605 -0.739744 0.286875 -1.16465 -0.021226 1.76007 -1.59538 -0.734425 0.499089 -0.452822 -1.19472 0.202749 -1.48974 0.7104 -0.163208 -0.851832 0.410502 0.460262 -0.585 -0.964066 -1.61492 0.205818 -0.452656 -0.324105 0.33743 0.971197 0.683796 -1.47611 -0.124408 0.114338 -0.588088 1.20729 0.634713 0.0514073 2.20227 1.73774 0.155452 0.686592 -0.594627 -0.910778 0.459221 0.373881 0.685625 0.179344 0.573614 0.601019 -0.718255 0.67973 -0.870696 -0.385222 0.80703 0.689814 1.4649 0.0548409 -1.12897 1.41573 -0.0800926 -0.802624 -0.308914 -0.440233 0.264821 -0.656492 0.0147298 -0.0521711 1.27813 1.94319 -1.2837 0.0309623 2.51247 0.166108 -2.18732 -0.97713 -1.05599 -0.721065 -0.413065 0.150855 1.91566 0.609684 -0.0353246 0.474814 0.0470938 1.23251 -0.175547 0.51923 0.214112 1.69798 1.34686 0.109449 0.573618 0.2769 -0.654584 -0.687492 0.431038 0.79963 0.603332 -1.08512 -0.139912 2.82884 1.75989 0.365692 0.975724 0.361237 0.162463 0.161993 0.0426663 -0.702214 0.703742 1.47992 -2.26304 0.194581 1.07627 0.21398 0.350251 0.422896 0.320611 -0.700118 -0.199322 1.22978 0.986192 2.23613 -0.583208 0.0872271 -0.0492896 0.250172 -1.04781 0.00570426 -0.998648 0.147468 -0.0228859 0.45162 0.864219 -0.987786 0.887656 1.16076 0.712473 0.184461 1.6548 -0.390376 1.79193 -2.63431 -0.262678 0.0621865 0.520317 -0.874701 0.54136 -0.590896 -0.159892 0.586547 0.478812 -1.19454 0.521406 -0.415431 2.76367 0.02572 0.691785 -0.87173 0.42869 0.795168 -1.80459 0.205468 -0.457023 -2.31281 -0.739941 2.16996 1.06709 -0.0510739 0.950573 -0.304595 1.58223 -0.0134787 0.592634 0.639719 0.738192 2.44702 0.666697 -0.22933 1.86072 -1.32142 -1.42401 0.693842 0.446999 -1.01884 2.33589 0.295524 -1.00314 0.181235 0.811825 -0.365703 0.397853 1.18496 -0.0160791 1.9323 0.586209 -0.233428 0.763706 -0.0463059 -0.933862 -0.148039 0.849203 1.12763 0.811968 0.96974 -1.66929 -1.22131 0.106182 0.551335 -1.2736 0.0311708 0.113346 0.674542 -0.126745 -0.858505 0.349372 -0.235143 -0.471285 0.23948 1.23881 -1.53004 -0.0412897 0.450115 -0.0609342 0.353603 -0.161616 -0.39965 1.77108 -0.122582 0.0197958 -0.371088 -0.28267 0.975808 0.447557 0.372401 0.474569 0.368497 0.270269 0.135105 -0.956495 -1.85926 0.0168665 1.40926 0.566392 -0.531227 0.345685 0.900056 -1.12487 1.53323 1.11767 -0.803823 0.91841 -0.311894 0.116547 -0.507071 -0.929834 0.882617 2.11902 0.254101 0.0250181 -0.438837 -0.393963 0.320266 -1.35553 0.195616 -0.168235 -0.472974 0.762692 0.183032 -0.457028 -0.359405 -0.677186 0.674699 0.758728 0.178162 -0.585807 2.12008 -0.214043 0.212605 -0.829978 0.73133 -1.75731 -0.454316 -0.861158 1.98868 0.150917 0.0197199 -1.49403 1.63714 0.644866 0.723228 -0.0197599 0.228231 -0.56468 -1.35785 -0.503019 0.532322 -0.0734055 0.281474 -0.10964 0.288563 0.0835159 -0.202425 -2.20548 0.760019 0.830932 0.944242 -1.47942 2.17867 -0.839541 1.08108 0.989927 0.179887 -0.0228488 0.892951 1.39628 -1.63418 0.524059</Parameters>
    </MultilayerPerceptron>
    <ProbabilisticLayer>
        <ProbabilisticNeuronsNumber>3</ProbabilisticNeuronsNumber>
        <ProbabilisticMethod>Probability</ProbabilisticMethod>
        <DecisionThreshold>0.5</DecisionThreshold>
    </ProbabilisticLayer>
    <Outputs>
        <OutputsNumber>3</OutputsNumber>
        <Item Index="1">
            <Name>output_1</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="2">
            <Name>output_2</Name>
            <Units></Units>
            <Description></Description>
        </Item>
        <Item Index="3">
            <Name>output_3</Name>
            <Units></Units>
            <Description></Description>
        </Item>
    </Outputs>
</NeuralNetwork>
